# Compiler

[![Go](https://github.com/iskorotkov/compiler/actions/workflows/go.yml/badge.svg)](https://github.com/iskorotkov/compiler/actions/workflows/go.yml)

Простой компилятор, разработанный в рамках курса "Формальные грамматики и методы трансляции".

## Сборка

Для сборки данного компилятора требуется [Go версии 1.18 или новее](https://go.dev/dl/).

Для получения бинарного файла (рекомендуется) выполните:

```shell
go build -o build cmd/compiler/main.go
```

Для запуска компилятора без создания бинарного файла выполните:

```shell
go run cmd/compiler/main.go
```

## Использование

Существует два способа запустить компилятор:

```shell
# Режим чтения из файла:
./compiler program.pas
# и режим чтения из стандартного ввода-вывода:
./compiler
```

Примеры запуска:

```shell
# Несуществующий файл или файл, к которому нет доступа
./compiler program.pas
> open program.pas: no such file or directory

# Файл с корректной программой:
./compiler program.pas
> compiled successfully

# Файл с некорректной программой:
./compiler program.pas
> "module" at 1:1-7: expected "program", got "module": unexpected token

# Чтение из стандартного ввода-вывода (корректная программа):
cat program.pas | ./compiler
> compiled successfully
```

## Архитектура

### Взаимодействие модулей

Планируется организовать взаимодействие различных модулей компилятора посредством передачи сообщений через каналы Go между горутинами. Каждый модуль запускается в отдельной горутине и работает параллельно с другими модулями, при этом он получает от предыдущего модуля данные по каналу, переданному ему в качестве параметра, а результаты своей работы передает в другой канал, который может использоваться другим модулем компилятора. Таким образом, работа компилятора организована по принципу конвейера.

![img.png](docs/img/goroutines.png)

Каждый модуль работает в отдельной горутине, и работа компилятора завершается, когда заканчивают свою работу все горутины (типично это должен быть последний модуль компилятора, осуществляющий вывод ошибок или результатов компиляции в зависимости от ее успеха).

На данный момент предлагается такой набор модулей:

[Reader (модуль ввода)](#reader) =>
[Scanner (сканер, лексический анализатор)](#scanner) =>
[Syntax analyzer (синтаксический анализатор)](#syntax-analyzer) =>
[Semantic analyzer (семантический анализатор)](#semantic-analyzer) =>
[Code generator (генератор кода)](#code-generator).

### Обработка ошибок

Любой из модулей может прервать работу конвейера при возникновении критической ошибки. В остальных случаях модуль передает ошибку дальше для обработки следующим модулем. Это возможно благодаря тому, что по каналам передаются не обязательно только результаты работы в случае успеха, а [дизъюнктивное объединение](https://ru.wikipedia.org/wiki/%D0%A2%D0%B8%D0%BF-%D1%81%D1%83%D0%BC%D0%BC%D0%B0) результата успеха и ошибки.

Требуется спроектировать вывод ошибок компиляции пользователю и механизм прерывания компиляции. Это планируется сделать после реализации лексического анализатора (т. к. тогда будет понятнее, какие ошибки и где возникают, а также будет возможность протестировать выбранный подход уже на практике).

### Reader

[Reader](internal/modules/reader/reader.go) читает файл построчно и каждую строку разбивает на части - литералы ([Literal](internal/data/literal/literal.go)). При этом все знаки препинания и даже переход на новую строку также сохраняются как отдельные части для последующего анализа в следующих модулях.

Reader указывает для каждого литерала строку, начальный и конечный столбец (начиная индексирование с 1) для того, чтобы в последующих модулях можно было указать на возникшую ошибку на основе этих данных в литерале.

Reader использует регулярные выражения для нахождения [несловообразующих символов](https://docs.microsoft.com/ru-ru/dotnet/standard/base-types/character-classes-in-regular-expressions). Это позволяет разбить прочитанную строку по ним и передать по частям следующим модулям.

### Scanner

[Scanner](internal/modules/scanner/scanner.go) читает литералы ([Literal](internal/data/literal/literal.go)) из канала, распознает их и записывает соответствующие им токены ([Token](internal/data/token/token.go)) в выходной канал с токенами. При получении ошибки из Reader она передается как есть далее. При невозможности распознать токен Scanner передает дальше ошибку и продолжает обработку следующих литералов.

Распознавание числовых и булевых констант производится с помощью регулярных выражений. Строковые константы на данный момент не поддерживаются.

Распознавание пользовательских идентификаторов производится с помощью регулярного выражения.

В исходном коде компилятора перечислены все используемые в языке Паскаль токены, а также для них созданы отображения из строк в уникальные идентификаторы и обратно, что позволяет не хранить и сравнивать строковые значения литералов, а использовать уникальные идентификаторы для этого.

Использование уникальных идентификаторов также упрощает определение того, с токеном какого типа мы работаем (например, ключевое слово или оператор).

### Syntax analyzer

[Syntax analyzer](internal/modules/syntax_analyzer/analyzer.go) читает токены из канала и использует описание синтаксиса языка для распознавания языковых конструкций и определения корректности поданной на вход программы.

#### БНФ

Синтаксис языка Паскаль описан в виде переменных, отражающих описание синтаксиса языка в формате БНФ из книги Л. Залоговой "Разработка Паскаль-компилятора". Все переменные удовлетворяют интерфейсу [BNF](internal/data/bnf/bnf.go) и имеют методы `String()` (для вывода в процессе отладки) и `Accept(log *zap.SugaredLogger, tokensCh *channel.TransactionChannel[option.Option[token.Token]]) error` для обработки поданных на вход токенов.

Для описания общих паттернов, используемых в БНФ, используюся вспомогательные структуры:

- [`Either`](internal/data/bnf/either.go) - один из вариантов (аналог `x|y` в БНФ)
- [`Optional`](internal/data/bnf/optional.go) - необязательное вхождение конструкции (аналог `[x]` в БНФ)
- [`Sequence`](internal/data/bnf/sequence.go) - последовательность конструкций
- [`Several`](internal/data/bnf/several.go) - вхождение конструкций 0 или более раз (аналог `{x}` в БНФ)
- [`Token`](internal/data/bnf/token.go) - обертка для одного токена

Каждая из этих структур определяет алгоритм обхода при обработке токенов и обработку ошибок в случае появления не той конструкции, которая ожидалась.

Организация описания синтаксиса языка в виде переменных-объектах, образующих граф объектов, позволяет обрабатывать токены декларативно, т. к. для добавления новых синтаксических возможностей (или отключения поддержки старых) необходимо только добавить или удалить переменную, или ее использование при инициализации других переменных.

#### Повторное чтение из канала

В данный момент все модули компилятора получают входные данные и возвращают результаты своей работы через каналы Go (Go channels), что накладывает некоторые ограничения при реализации этих модулей. Например, синтаксический анализатор при своей работе в некоторых случаях должен уметь откатываться назад и перечитывать некоторые токены повторно и в разных местах в коде, т. к. некоторые конструкции (например, [`Optional`](internal/data/bnf/optional.go) и [`Several`](internal/data/bnf/several.go)) читают токен, но не должны его поглощать при несовпадении токена с ожидаемым набором токенов. Каналы в Go не позволяют вернуть считанное значение обратно в начало канала.

Для обхода подобного ограничения в синтаксическом анализаторе решено использовать обертку вокруг каналов Go - структуру [`TxChannel[T any]`](internal/fn/channels/tx.go). Она предоставляет следующие методы:

- `Read` - чтение из канала
- `Open` - проверка открытости канала
- `StartTx` - начало новой транзакции (транзакции могут быть вложенными)
- `Commit` - подтверждение всех чтений последней транзакции (т. е. все чтения с момента начала предыдущей транзакции нельзя будет отменить)
- `Rollback` - откат всех чтений предыдущей транзакции (т. е. все прочитанные значения с момента начала предыдущей транзакции могут быть прочитаны заново в том же порядке)

Такая структура позволяет читать последовательности токенов неограниченное количество раз в исходном порядке.

### Semantic analyzer

### Code generator

## Нейтрализация ошибок

## Тестирование

В процессе реализации модулей компилятора к ним также пишутся юнит-тесты для проверки их корректной работы. Часть тестов для модуля Reader написаны классическим способом, но большая часть тестов используют снапшоты для сравнения результатов выполнения.

При первом выполнении теста сохраненного снапшота нет и поэтому тест всегда проходит и сохраняет снапшот результата вызова тестируемой функции в файл. При последующих запусках снапшот читается из файла и сравнивается с результатов вызова тестируемой функции, и если есть какие-либо различия, то тест отмечается проваленным. Данный подход позволяет избежать времязатратного описания ожидаемого результата в коде, т. к. сравниваются эталонное решение из снапшота и текущий результат. Вручную проверить эталонное решение, записанное в файле, намного проще, чем описывать его в коде и менять каждый раз при изменении особенностей реализации модулей.

## Отладка

Компилятор в ходе работы выводит в лог информацию для отладки, если при запуске компилятора переменная окружения `DEBUG` имеет значение `1`. Это позволяет значительно проще и быстрее обнаружить, локализовать и устранить ошибку в реализации компилятора. Кроме того, компилятор не засоряет логами вывод, если переменная `DEBUG` не установлена или установлена в другое значение, что улучшает UX.

## CI/CD

При каждом пуше в ветку `main` GitHub собирает и тестирует компилятор. Для каждого PR GitHub также собирает и тестирует компилятор, что позволяет обнаружить ошибки в реализации до слияния ветки.
